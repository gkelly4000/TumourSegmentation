{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjtM633FmQAH",
        "outputId": "4bfe4164-7a01-486c-b289-c55b369626fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Google drive authentication (for use with google colab).\n",
        "from google.convLayeronvLayerolab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgRbPLADmRSk",
        "outputId": "3ff5141c-9f38-453c-be20-ac4e96835639"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-24 15:55:02.416446: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2022-06-24 15:55:02.416492: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Segmentation Models: using `tf.keras` framework.\n"
          ]
        }
      ],
      "source": [
        "# Library imports\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model, utils\n",
        "from tensorflow.keras.layers import Conv3D, MaxPool3D, UpSampling3D, concatenate, BatchNormalization,Activation,Concatenate,Conv2DTranspose,Input,Conv3DTranspose,MaxPooling3D,Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "import segmentation_models_3D as sm\n",
        "\n",
        "import random \n",
        "\n",
        "from tensorflow.keras import backend as K "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fkIZGheJvo3"
      },
      "outputs": [],
      "source": [
        "# Function to create a filename for the brats 2021 dataset\n",
        "def nameBuilder(num):\n",
        "  baseName = \"BraTS2021_\"\n",
        "  name = baseName + num.zfill(5)\n",
        "  return name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r8LIY9dCCAI",
        "outputId": "73b2fc09-cce5-4bd5-8289-36f49c9cf458"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "920\n",
            "115\n"
          ]
        }
      ],
      "source": [
        "# Function to create lists of file directories to be passed into the data generator\n",
        "\n",
        "trainList = os.listdir(\"/content/drive/MyDrive/output/train/image\")\n",
        "valList = os.listdir(\"/content/drive/MyDrive/output/val/image\")\n",
        "testList = os.listdir(\"/content/drive/MyDrive/output/test/image\")\n",
        "\n",
        "trainImageList = []\n",
        "trainMaskList = []\n",
        "\n",
        "valImageList = []\n",
        "valMaskList = []\n",
        "\n",
        "testImageList = []\n",
        "testMaskList = []\n",
        "\n",
        "l = len(trainList) \n",
        "for i in range(l):\n",
        "  num = (trainList[i].split(\"_\")[1])\n",
        "  name = (nameBuilder(num))\n",
        "  trainImageList.append(os.path.join(\"/content/drive/MyDrive/output/train/image\", name +\"_image.npy\"))\n",
        "  trainMaskList.append(os.path.join(\"/content/drive/MyDrive/output/train/mask\", name +\"_mask.npy\"))\n",
        "\n",
        "\n",
        "l = len(valList) \n",
        "for i in range(l):\n",
        "  num = (valList[i].split(\"_\")[1])\n",
        "  name = (nameBuilder(num))\n",
        "  valImageList.append(os.path.join(\"/content/drive/MyDrive/output/val/image\", name +\"_image.npy\"))\n",
        "  valMaskList.append(os.path.join(\"/content/drive/MyDrive/output/val/mask\", name +\"_mask.npy\"))\n",
        "\n",
        "l = len(testList) \n",
        "for i in range(l):\n",
        "  num = (testList[i].split(\"_\")[1])\n",
        "  name = (nameBuilder(num))\n",
        "  testImageList.append(os.path.join(\"/content/drive/MyDrive/output/test/image\", name +\"_image.npy\"))\n",
        "  testMaskList.append(os.path.join(\"/content/drive/MyDrive/output/test/mask\", name +\"_mask.npy\"))\n",
        "del(trainList)\n",
        "del(valList)\n",
        "del(testList)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoEtSYSRSNrr"
      },
      "outputs": [],
      "source": [
        "# Data generator functions\n",
        "\n",
        "def load(imgList):\n",
        "    list = []\n",
        "    for img in imgList:\n",
        "        img = np.load(img)\n",
        "        list.append(img)\n",
        "    arr = np.array(list)\n",
        "    return arr\n",
        "\n",
        "def imageGenertor(batchSize, imageList, maskList):\n",
        "\n",
        "    length = len(imageList)\n",
        "    while True:\n",
        "        start = 0\n",
        "        end = batchSize\n",
        "\n",
        "        while start < length:\n",
        "            x = load(imageList[start:min(end, length)])\n",
        "            y = load(maskList[start:min(end, length)])\n",
        "            \n",
        "            yield(x,y)\n",
        "\n",
        "            start += batchSize\n",
        "            end += batchSize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vbjxo8L6ynRW"
      },
      "outputs": [],
      "source": [
        "# U-Net model defined using Tensorflow and Keras\n",
        "\n",
        "def segmentationModel(HEIGHT, WIDTH, DEPTH, CHANNELS, CLASSES):\n",
        "\n",
        "    input = Input((HEIGHT, WIDTH, DEPTH, CHANNELS))\n",
        "\n",
        "    kernel_initializer =  'he_uniform'\n",
        "\n",
        "    convLayer1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(input)\n",
        "    convLayer1 = Dropout(0.1)(convLayer1)\n",
        "    convLayer1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(convLayer1)\n",
        "    pool1 = MaxPooling3D((2, 2, 2))(convLayer1)\n",
        "    \n",
        "    convLayer2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(pool1)\n",
        "    convLayer2 = Dropout(0.1)(convLayer2)\n",
        "    convLayer2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(convLayer2)\n",
        "    pool2 = MaxPooling3D((2, 2, 2))(convLayer2)\n",
        "     \n",
        "    convLayer3 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(pool2)\n",
        "    convLayer3 = Dropout(0.2)(convLayer3)\n",
        "    convLayer3 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(convLayer3)\n",
        "    pool3 = MaxPooling3D((2, 2, 2))(convLayer3)\n",
        "     \n",
        "    convLayer4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(pool3)\n",
        "    convLayer4 = Dropout(0.2)(convLayer4)\n",
        "    convLayer4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(convLayer4)\n",
        "    pool4 = MaxPooling3D(pool_size=(2, 2, 2))(convLayer4)\n",
        "     \n",
        "    convLayer5 = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(pool4)\n",
        "    convLayer5 = Dropout(0.3)(convLayer5)\n",
        "    convLayer5 = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(convLayer5)\n",
        "    \n",
        "    upSample1 = Conv3DTranspose(128, (2, 2, 2), strides=(2, 2, 2), padding='same')(convLayer5)\n",
        "    upSample1 = concatenate([upSample1, convLayer4])\n",
        "    convLayer6 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(upSample1)\n",
        "    convLayer6 = Dropout(0.2)(convLayer6)\n",
        "    convLayer6 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(convLayer6)\n",
        "     \n",
        "    upSample2 = Conv3DTranspose(64, (2, 2, 2), strides=(2, 2, 2), padding='same')(convLayer6)\n",
        "    upSample2 = concatenate([upSample2, convLayer3])\n",
        "    convLayer7 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(upSample2)\n",
        "    convLayer7 = Dropout(0.2)(convLayer7)\n",
        "    convLayer7 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(convLayer7)\n",
        "     \n",
        "    upSample3 = Conv3DTranspose(32, (2, 2, 2), strides=(2, 2, 2), padding='same')(convLayer7)\n",
        "    upSample3 = concatenate([upSample3, convLayer2])\n",
        "    convLayer8 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(upSample3)\n",
        "    convLayer8 = Dropout(0.1)(convLayer8)\n",
        "    convLayer8 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(convLayer8)\n",
        "     \n",
        "    upSample4 = Conv3DTranspose(16, (2, 2, 2), strides=(2, 2, 2), padding='same')(convLayer8)\n",
        "    upSample4 = concatenate([upSample4, convLayer1])\n",
        "    convLayer9 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(upSample4)\n",
        "    convLayer9 = Dropout(0.1)(convLayer9)\n",
        "    convLayer9 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(convLayer9)\n",
        "     \n",
        "    outputs = Conv3D(CLASSES, (1, 1, 1), activation='softmax')(convLayer9)\n",
        "     \n",
        "    model = Model(inputs=[input], outputs=[outputs])    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = np.stack([image, image, image, image], axis=3)\n",
        "# hStart = int((height - 128) / 2)\n",
        "# hEnd = int((height - ((height-128) / 2)))\n",
        "\n",
        "# wStart = int((width - 128) / 2)\n",
        "# wEnd = int((width - ((width-128) / 2)))\n",
        "\n",
        "# dStart = int((depth - 128) / 2)\n",
        "# dEnd = int((depth - ((depth-128) / 2)))\n",
        "\n",
        "# print(hStart, hEnd)\n",
        "# print(wStart, wEnd)\n",
        "# print(dStart, dEnd)\n",
        "# # 56:184, 56:184, 13:141"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(128, 128, 128, 4)\n"
          ]
        }
      ],
      "source": [
        "image = image[hStart:hEnd, wStart:wEnd, dStart:dEnd]\n",
        "print(image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJbXfBGpgcU4"
      },
      "outputs": [],
      "source": [
        "# Import and define loss function\n",
        "\n",
        "import segmentation_models_3D as sm\n",
        "diceLoss = sm.losses.DiceLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    \"\"\"_summary_\n",
        "    Dice Coefficienet function for single class data\n",
        "    Adapted from: https://stackoverflow.com/questions/61488732/how-calculate-the-dice-coefficient-for-multi-class-segmentation-task-using-pytho\n",
        "\n",
        "    Args:\n",
        "        y_true (_type_): _description_\n",
        "        y_pred (_type_): _description_\n",
        "\n",
        "    Returns:\n",
        "        _type_: _description_\n",
        "    \"\"\"\n",
        "    y_true_f = y_true.flatten()\n",
        "    y_pred_f = y_pred.flatten()\n",
        "    intersection = np.sum(y_true_f * y_pred_f)\n",
        "    smooth = 0.0001\n",
        "    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_coef_multilabel(y_true, y_pred, numLabels):\n",
        "    \"\"\"_summary_\n",
        "    Dice Coefficienet function for multi class data\n",
        "    Adapted from: https://stackoverflow.com/questions/61488732/how-calculate-the-dice-coefficient-for-multi-class-segmentation-task-using-pytho\n",
        "\n",
        "    Args:\n",
        "        y_true (_type_): _description_\n",
        "        y_pred (_type_): _description_\n",
        "        numLabels (_type_): _description_\n",
        "\n",
        "    Returns:\n",
        "        _type_: _description_\n",
        "    \"\"\"\n",
        "    if y_true.shape != (128,128,128) or y_pred.shape != (128,128,128):\n",
        "        return False\n",
        "    y_true = to_categorical(y_true, num_classes=numLabels)\n",
        "    y_pred = to_categorical(y_pred, num_classes=numLabels)\n",
        "    dice=0\n",
        "    for index in range(numLabels):\n",
        "        dice += dice_coef(y_true[:,:,:,index], y_pred[:,:,:,index])\n",
        "    return dice/numLabels "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To_D803HV3YM"
      },
      "outputs": [],
      "source": [
        "# Define model\n",
        "model = segmentationModel(128, 128, 128, 4, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSkKZds2cr0B"
      },
      "outputs": [],
      "source": [
        "# Define batchsize and data generator objects for the training and validation sets\n",
        "\n",
        "batchSize = 4\n",
        "datagen = imageGenertor(batchSize, \"/content/drive/MyDrive/output/train\",trainImageList, trainMaskList)\n",
        "# img, msk = datagen.__next__()\n",
        "# print(img.shape)\n",
        "# print(msk.shape)\n",
        "valdatagen = imageGenertor(batchSize, \"/content/drive/MyDrive/output/val\",valImageList, valMaskList)\n",
        "# vimg, vmsk = valdatagen.__next__()\n",
        "# print(vimg.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESeURaQGSgAg",
        "outputId": "3d1a86e6-87f0-415b-a384-33a73ed5bd71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "  2/230 [..............................] - ETA: 6:31 - loss: 1.3508 - dice_coefficient: 0.1198   "
          ]
        }
      ],
      "source": [
        "# Training or fitting the model to a training dataset\n",
        "\n",
        "steps = len(trainImageList) // batchSize\n",
        "valsteps =  len(valImageList) // batchSize\n",
        "epochs = 10\n",
        "modelSaveName = \"segmentationModel\" \n",
        "\n",
        "# For use when retraining a previsouly trained model\n",
        "# model = load_model(\"/content/drive/MyDrive/models/cross15\", custom_objects={'loss': tf.keras.losses.CategoricalCrossentropy, 'dice_coefficient':dice_coefficient})\n",
        "\n",
        "# Compile the model \n",
        "model.compile(optimizer='Adam',loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[dice_coef_multilabel])\n",
        "\n",
        "# Fit the model, saving training metrics in history variable\n",
        "history = model.fit(x=datagen,steps_per_epoch=steps, validation_data=valdatagen, validation_steps=valsteps, epochs=epochs, verbose=1)\n",
        "\n",
        "# Save the model\n",
        "model.save(f\"/content/drive/MyDrive/models/{modelSaveName}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "fNV4Q8kTQ0pr",
        "outputId": "6604aa2a-13bb-46b3-d6dc-435acd54eb7f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9d23038f94c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/content/drive/MyDrive/models/{modelSaveName}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "model.save(f\"/content/drive/MyDrive/models/{modelSaveName}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-8eIhNJjRa2"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "path = \"/content/drive/MyDrive/RAWDATA/MICCAI_BraTS2020_ValidationData\"\n",
        "total = (len(os.listdir(path)))\n",
        "dir = os.listdir(path)\n",
        "num = 0\n",
        "for d in dir:\n",
        "    num += 1\n",
        "    curPath = os.path.join(path, d)\n",
        "    # Flair\n",
        "    flairPath = os.path.join(curPath, d+\"_flair.nii\")\n",
        "    flairImage = nib.load(flairPath).get_fdata()\n",
        "    scaledFlair = scaler.fit_transform(flairImage.reshape(-1, flairImage.shape[-1])).reshape(flairImage.shape)\n",
        "    # flairImage = scaler.fit_transform(flairImage.reshape(-1, flairImage.shape[-1])).reshape(flairImage.shape)\n",
        "    \n",
        "    # T1CE\n",
        "    t1cePath = os.path.join(curPath, d+\"_t1ce.nii\")\n",
        "    t1ceImage = nib.load(t1cePath).get_fdata()\n",
        "    scaledT1ce = scaler.fit_transform(t1ceImage.reshape(-1, t1ceImage.shape[-1])).reshape(t1ceImage.shape)\n",
        "\n",
        "    #T1\n",
        "    t1Path = os.path.join(curPath, d+\"_t1.nii\")\n",
        "    t1Image = nib.load(t1Path).get_fdata()\n",
        "    scaledT1 = scaler.fit_transform(t1Image.reshape(-1, t1Image.shape[-1])).reshape(t1Image.shape)\n",
        "\n",
        "    # T2\n",
        "    t2Path = os.path.join(curPath, d+\"_t2.nii\")\n",
        "    t2Image = nib.load(t2Path).get_fdata()\n",
        "    scaledT2 = scaler.fit_transform(t2Image.reshape(-1, t2Image.shape[-1])).reshape(t2Image.shape)\n",
        "\n",
        "    \n",
        "   \n",
        "\n",
        "    # # Mask\n",
        "    # maskPath = os.path.join(curPath, d + \"_seg.nii.gz\")\n",
        "    # maskImage = nib.load(maskPath).get_fdata()\n",
        "    # maskImage = maskImage.astype(np.uint8)\n",
        "    # maskImage[maskImage==4] = 3\n",
        "\n",
        "    # Combine Modalities\n",
        "\n",
        "    combinedImage = np.stack([scaledFlair, scaledT1ce, scaledT1, scaledT2], axis=3)\n",
        "\n",
        "\n",
        "    # Crop volumes to 128x128x128\n",
        "    combinedImage = combinedImage[56:184, 56:184, 13:141]\n",
        "    # maskImage = maskImage[56:184, 56:184, 13:141]\n",
        "\n",
        "\n",
        "    print(f\"Saved: {num} out of {total}\")\n",
        "    # Save as numpy arrays\n",
        "    imageSavePath = \"/content/drive/MyDrive/VAL/image\"\n",
        "    imageSaveName = d + \"_image\"\n",
        "    print(imageSaveName)\n",
        "    np.save(os.path.join(imageSavePath, imageSaveName), combinedImage)\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    values, counts = np.unique(maskImage, return_counts=True)\n",
        "\n",
        "    if (1 - (counts[0]/counts.sum())) > 0.01:\n",
        "        print(f\"Saved: {num} out of {total}\")\n",
        "         # Save as numpy arrays\n",
        "        imageSavePath = \"/content/drive/MyDrive/data2/image\"\n",
        "        imageSaveName = d + \"_image\"\n",
        "        np.save(os.path.join(imageSavePath, imageSaveName), combinedImage)\n",
        "\n",
        "        maskSavePath = \"/content/drive/MyDrive/data2/mask\"\n",
        "        maskSaveName = d + \"_mask\"\n",
        "        maskImage = to_categorical(maskImage, num_classes=4)#.astype(np.uint8)\n",
        "        np.save(os.path.join(maskSavePath, maskSaveName), maskImage)\n",
        "        \n",
        "     \n",
        "        \n",
        "   \n",
        "  \n",
        "    "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "mri2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
